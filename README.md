---
title: Memora
emoji: ğŸ§ 
colorFrom: purple
colorTo: blue
sdk: streamlit
sdk_version: 1.28.0
app_file: app.py
pinned: false
license: mit
---

# ğŸ§  Memora

> **Your AI Assistant with Long-term Memory**

An intelligent AI assistant that **remembers** your conversations, preferences, and important information across sessions. Built with Python, LangChain, ChromaDB, and supports both local and **FREE cloud** LLMs.

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![LangChain](https://img.shields.io/badge/LangChain-0.1+-green.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

<p align="center">
  <img src="https://img.shields.io/github/stars/Manju1303/Memora?style=social" alt="Stars">
  <img src="https://img.shields.io/github/forks/Manju1303/Memora?style=social" alt="Forks">
</p>

---

## ğŸŒ Try It Online (FREE!)

**Deploy to Streamlit Cloud in minutes - completely FREE!**

[![Deploy to Streamlit](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://share.streamlit.io/deploy)

1. Fork this repo
2. Go to [share.streamlit.io](https://share.streamlit.io)
3. Connect your GitHub and select the Memora repo
4. Add your FREE Hugging Face token in Secrets (see below)
5. Deploy!

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ’¬ **Smart Conversations** | Context-aware multi-turn dialogue |
| ğŸ§  **Long-term Memory** | Remembers across sessions using vector DB |
| ğŸ¤ **Voice Input** | Speak instead of typing (local only) |
| ğŸ”Š **Voice Output** | Listen to responses (local only) |
| ğŸ” **Semantic Search** | Find memories by meaning, not keywords |
| â˜ï¸ **Cloud Deployment** | Deploy FREE on Streamlit Cloud |
| ğŸ‘¤ **Personalization** | Adapts to your preferences |

---

## ğŸ¬ Demo

```
You: My name is Alex and I love Python programming.
Memora: Nice to meet you, Alex! Python is a great choice...

[After restarting the app]

You: What's my name?
Memora: Your name is Alex! You mentioned you love Python programming.
```

---

## ğŸš€ Deployment Options

### Option 1: â˜ï¸ Cloud (FREE - Recommended!)

Deploy on **Streamlit Community Cloud** with **Hugging Face** (both FREE):

1. **Get FREE Hugging Face Token:**
   - Go to [huggingface.co](https://huggingface.co) and create free account
   - Navigate to Settings â†’ Access Tokens
   - Create a new token (free!)

2. **Deploy to Streamlit Cloud:**
   - Fork this repository
   - Go to [share.streamlit.io](https://share.streamlit.io)
   - Click "New app" â†’ Select your fork
   - Add secrets in Advanced Settings:
     ```toml
     HF_TOKEN = "your-free-token-here"
     LLM_PROVIDER = "huggingface"
     ```
   - Deploy!

### Option 2: ğŸ’» Local (Full Features)

Run locally with Ollama for voice features:

```bash
# Clone the repository
git clone https://github.com/Manju1303/Memora.git
cd Memora

# Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt

# Setup Ollama (download from https://ollama.ai)
ollama pull mistral
ollama serve

# Run Memora
streamlit run app.py
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Streamlit Frontend                        â”‚
â”‚        Chat UI  |  Voice Controls  |  Memory Viewer         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      LangChain Agent                         â”‚
â”‚              RAG Engine  |  Memory Manager                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Provider   â”‚  â”‚ Short-term  â”‚  â”‚ ChromaDB (Vector)   â”‚
â”‚ HuggingFace/    â”‚  â”‚ Memory      â”‚  â”‚ Long-term Memory    â”‚
â”‚ Ollama          â”‚  â”‚             â”‚  â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
memora/
â”œâ”€â”€ app.py                    # ğŸ–¥ï¸ Streamlit UI
â”œâ”€â”€ config.py                 # âš™ï¸ Settings
â”œâ”€â”€ requirements.txt          # ğŸ“¦ Dependencies
â”‚
â”œâ”€â”€ agent/                    # ğŸ¤– AI Logic
â”‚   â”œâ”€â”€ core.py               # Main agent (RAG)
â”‚   â”œâ”€â”€ memory_manager.py     # Memory orchestration
â”‚   â””â”€â”€ prompts.py            # Prompt templates
â”‚
â”œâ”€â”€ memory/                   # ğŸ’¾ Memory Systems
â”‚   â”œâ”€â”€ short_term.py         # Recent context
â”‚   â”œâ”€â”€ long_term.py          # Vector storage
â”‚   â””â”€â”€ summarizer.py         # Fact extraction
â”‚
â”œâ”€â”€ voice/                    # ğŸ¤ Voice Features (local only)
â”‚   â”œâ”€â”€ speech_to_text.py     # Whisper STT
â”‚   â””â”€â”€ text_to_speech.py     # pyttsx3 TTS
â”‚
â””â”€â”€ docs/
    â””â”€â”€ PROJECT_DESCRIPTION.md # ğŸ“š Full documentation
```

---

## âš™ï¸ Configuration

Edit `config.py` or use Streamlit secrets:

```python
# Cloud (FREE)
LLM_PROVIDER = "huggingface"
HF_TOKEN = "your-free-token"

# Local
LLM_PROVIDER = "ollama"
OLLAMA_MODEL = "mistral"
```

---

## ğŸ¯ Use Cases

- ğŸ“š **Study Companion** - Remembers what you've learned
- ğŸ’¼ **Personal Assistant** - Tracks your preferences
- ğŸ‘¨â€ğŸ’» **Coding Helper** - Recalls your project context
- ğŸ“ **Note Taking** - Never forget important info

---

## ğŸ”§ Algorithms

| Algorithm | Purpose | File |
|-----------|---------|------|
| **RAG** | Memory-augmented generation | `agent/core.py` |
| **Vector Similarity** | Semantic memory search | `memory/long_term.py` |
| **Sliding Window** | Recent context tracking | `memory/short_term.py` |
| **Abstractive Summarization** | Fact extraction | `memory/summarizer.py` |

---

## ğŸ†“ Cost Breakdown

| Component | Cost |
|-----------|------|
| Streamlit Cloud Hosting | **FREE** |
| Hugging Face API | **FREE** |
| ChromaDB | **FREE** |
| Total | **$0/month** |

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [LangChain](https://langchain.com) - Agent framework
- [ChromaDB](https://www.trychroma.com) - Vector database
- [Hugging Face](https://huggingface.co) - FREE cloud LLMs
- [Ollama](https://ollama.ai) - Local LLM runtime
- [Streamlit](https://streamlit.io) - UI framework & FREE hosting

---

<p align="center">
  Made with â¤ï¸ | 100% FREE and Open Source
</p>
